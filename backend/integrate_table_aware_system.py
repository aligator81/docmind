"""
Integration script for table-aware chunking system

This script integrates the enhanced table processing capabilities
with the existing document processing pipeline.
"""

import os
import sys
import logging
from pathlib import Path

# Add the backend directory to Python path
sys.path.insert(0, str(Path(__file__).parent))

from app.services.enhanced_document_processor import EnhancedDocumentProcessor
from app.services.table_aware_chunker import TableAwareChunker
from app.services.document_processor import DocumentProcessor
from app.services.improved_chunker import ImprovedDocumentChunker

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def compare_chunking_methods():
    """Compare original vs enhanced chunking methods"""
    print("üîç Comparing Chunking Methods")
    print("=" * 60)
    
    # Test content with complex tables
    test_content = """
# Financial Report Q3 2024

## Executive Summary

The company showed strong performance in Q3 2024 with revenue growth across all segments.

<!-- TABLE_START: financial_summary -->
**Table 1**: Financial Performance Summary
Extracted with text_based method, confidence: 0.82
Page 1

| Metric | Q1 2024 | Q2 2024 | Q3 2024 | Growth Q3 vs Q2 |
|--------|---------|---------|---------|----------------|
| Revenue | 1,200,000 | 1,350,000 | 1,520,000 | +12.6% |
| Net Income | 180,000 | 210,000 | 245,000 | +16.7% |
| Gross Margin | 42.5% | 43.2% | 44.1% | +0.9% |
| Operating Expenses | 320,000 | 345,000 | 365,000 | +5.8% |
<!-- TABLE_END: financial_summary -->

## Regional Performance

The following table shows performance by region:

<!-- TABLE_START: regional_performance -->
**Table 2**: Regional Performance Metrics
Extracted with pattern_based method, confidence: 0.78
Page 2

| Region | Revenue Q3 | Revenue Q2 | Growth | Market Share | Customer Count | Avg. Revenue per Customer |
|--------|------------|------------|--------|--------------|----------------|---------------------------|
| North America | 650,000 | 580,000 | +12.1% | 42.8% | 12,500 | 52.00 |
| Europe | 420,000 | 385,000 | +9.1% | 27.6% | 8,200 | 51.22 |
| Asia Pacific | 280,000 | 245,000 | +14.3% | 18.4% | 6,800 | 41.18 |
| Latin America | 120,000 | 105,000 | +14.3% | 7.9% | 3,500 | 34.29 |
| Middle East | 50,000 | 35,000 | +42.9% | 3.3% | 1,200 | 41.67 |
<!-- TABLE_END: regional_performance -->

## Conclusion

The company continues to show strong growth across all regions.
"""

    filename = "financial_report_q3_2024.md"
    
    # Test with original chunker
    print("\nüìä Original Chunker Results:")
    original_chunker = ImprovedDocumentChunker()
    original_chunks = original_chunker.split_content_into_chunks(test_content, filename)
    
    print(f"  - Total chunks: {len(original_chunks)}")
    
    # Count table-related chunks in original
    original_table_chunks = [chunk for chunk in original_chunks 
                           if 'table' in chunk.get('chunk_text', '').lower()]
    print(f"  - Table-related chunks: {len(original_table_chunks)}")
    
    # Test with enhanced chunker
    print("\nüìä Enhanced Table-Aware Chunker Results:")
    enhanced_chunker = TableAwareChunker()
    enhanced_chunks = enhanced_chunker.split_content_into_chunks(test_content, filename)
    
    print(f"  - Total chunks: {len(enhanced_chunks)}")
    
    # Count table-specific chunks
    table_chunks = [chunk for chunk in enhanced_chunks 
                   if chunk.get('chunk_type', '').startswith('table_')]
    text_chunks = [chunk for chunk in enhanced_chunks 
                  if not chunk.get('chunk_type', '').startswith('table_')]
    
    print(f"  - Table chunks: {len(table_chunks)}")
    print(f"  - Text chunks: {len(text_chunks)}")
    
    # Show table chunk details
    print(f"  - Table chunk types:")
    chunk_types = {}
    for chunk in table_chunks:
        chunk_type = chunk.get('chunk_type', 'unknown')
        chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1
    
    for chunk_type, count in chunk_types.items():
        print(f"    - {chunk_type}: {count}")
    
    # Validate table chunks
    validation = enhanced_chunker.validate_table_chunks(enhanced_chunks)
    print(f"  - Table chunk validation:")
    print(f"    - Average confidence: {validation['average_confidence']:.2f}")
    print(f"    - Issues: {validation['issues']}")
    
    return original_chunks, enhanced_chunks

def integrate_with_existing_pipeline():
    """Integrate enhanced processor with existing pipeline"""
    print("\nüîÑ Integrating with Existing Pipeline")
    print("=" * 60)
    
    # Test with existing document processor
    print("\nüìÑ Testing Enhanced Document Processor:")
    
    # Create test document if it doesn't exist
    test_doc_path = "data/uploads/test_financial.md"
    os.makedirs(os.path.dirname(test_doc_path), exist_ok=True)
    
    test_content = """
# Test Financial Document

This document contains financial tables for testing.

<!-- TABLE_START: test_table -->
**Table 1**: Test Financial Data
Extracted with text_based method, confidence: 0.85
Page 1

| Category | Q1 | Q2 | Q3 | Q4 |
|----------|----|----|----|----|
| Revenue | 1000 | 1200 | 1400 | 1600 |
| Expenses | 600 | 650 | 700 | 750 |
| Profit | 400 | 550 | 700 | 850 |
<!-- TABLE_END: test_table -->

End of document.
"""
    
    with open(test_doc_path, 'w', encoding='utf-8') as f:
        f.write(test_content)
    
    try:
        # Test with enhanced processor
        enhanced_processor = EnhancedDocumentProcessor()
        enhanced_result = enhanced_processor.process_document(test_doc_path)
        
        print(f"‚úÖ Enhanced processing completed")
        print(f"  - Total chunks: {len(enhanced_result.get('chunks', []))}")
        print(f"  - Tables extracted: {len(enhanced_result.get('tables', []))}")
        print(f"  - Quality score: {enhanced_result.get('quality_score', 0):.2f}")
        
        # Show table details
        tables = enhanced_result.get('tables', [])
        for i, table in enumerate(tables):
            print(f"  - Table {i+1}:")
            print(f"    - Complexity: {table.get('complexity', 'unknown')}")
            print(f"    - Rows: {len(table.get('rows', []))}")
            print(f"    - Columns: {len(table.get('headers', []))}")
            print(f"    - Confidence: {table.get('confidence_score', 0):.2f}")
        
    except Exception as e:
        print(f"‚ùå Error in enhanced processing: {e}")
    
    finally:
        # Clean up test file
        if os.path.exists(test_doc_path):
            os.remove(test_doc_path)

def create_migration_guide():
    """Create migration guide for switching to table-aware system"""
    print("\nüìã Migration Guide")
    print("=" * 60)
    
    guide = """
## Migration to Table-Aware Chunking System

### 1. Update Imports
```python
# Before
from app.services.document_processor import DocumentProcessor
from app.services.improved_chunker import ImprovedDocumentChunker

# After  
from app.services.enhanced_document_processor import EnhancedDocumentProcessor
from app.services.table_aware_chunker import TableAwareChunker
```

### 2. Update Processing Code
```python
# Before
processor = DocumentProcessor()
chunker = ImprovedDocumentChunker()

# After
processor = EnhancedDocumentProcessor()  # Enhanced table extraction
chunker = TableAwareChunker()           # Table-aware chunking
```

### 3. Enhanced Configuration
```python
# Table-aware chunker configuration
chunker = TableAwareChunker()
chunker.max_rows_per_chunk = 10        # Rows per table chunk
chunker.max_columns_per_chunk = 4      # Columns per table chunk  
chunker.min_table_chunk_size = 100     # Minimum table chunk size
```

### 4. Quality Monitoring
```python
# Validate table chunks
validation = chunker.validate_table_chunks(chunks)
print(f"Table chunk quality: {validation['average_confidence']:.2f}")
print(f"Issues: {validation['issues']}")
```

### 5. Benefits
- ‚úÖ Preserves table structure in embeddings
- ‚úÖ Better AI responses for table-based queries
- ‚úÖ Automatic table complexity assessment
- ‚úÖ Multiple chunking strategies for different table types
- ‚úÖ Quality validation and confidence scoring
"""
    
    print(guide)

def run_integration_test():
    """Run complete integration test"""
    print("üöÄ Starting Table-Aware System Integration")
    print("=" * 60)
    
    # Compare methods
    original_chunks, enhanced_chunks = compare_chunking_methods()
    
    # Test integration
    integrate_with_existing_pipeline()
    
    # Create migration guide
    create_migration_guide()
    
    print("\n" + "=" * 60)
    print("üéØ Integration Summary:")
    print("‚úÖ Table-aware chunking preserves table structure")
    print("‚úÖ Multiple chunking strategies for different table types") 
    print("‚úÖ Quality validation and confidence scoring")
    print("‚úÖ Seamless integration with existing pipeline")
    print("‚úÖ Migration guide created for easy adoption")
    
    print("\nüìä Performance Comparison:")
    print(f"  - Original chunks: {len(original_chunks)}")
    print(f"  - Enhanced chunks: {len(enhanced_chunks)}")
    print(f"  - Table structure preservation: ‚úÖ Enabled")
    print(f"  - Quality validation: ‚úÖ Available")

if __name__ == "__main__":
    run_integration_test()